{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom sklearn.utils import shuffle, resample\n\nimport math\nimport shutil\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras.utils import np_utils\n\nimport torch \nimport torch.nn as nn \nfrom torch.nn import functional as F\nfrom torch import optim\nimport torchmetrics\nimport torchvision\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader, random_split\nfrom torchmetrics import Accuracy\nfrom torchvision import transforms\n\n\nfrom pytorch_lightning import LightningModule, Trainer, seed_everything\nfrom pytorch_lightning.callbacks.progress import TQDMProgressBar\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import Callback, ModelCheckpoint, EarlyStopping\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-09T03:48:02.067050Z","iopub.execute_input":"2023-01-09T03:48:02.067484Z","iopub.status.idle":"2023-01-09T03:48:02.093834Z","shell.execute_reply.started":"2023-01-09T03:48:02.067446Z","shell.execute_reply":"2023-01-09T03:48:02.092988Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/nn-real-data-train-d1s1-1/real_labels_tr_d1s1.csv\n/kaggle/input/nn-real-data-train-d1s1-1/real_signals_tr_d1s1.csv\n/kaggle/input/nn-test-data-2/scrappie_labels.csv\n/kaggle/input/nn-test-data-2/scrappie_signals.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class Squiggles(Dataset):\n    def __init__(self, signals, labels, trn_val_tst = 0, train_perc = 0.4, valid_perc = 0.6):\n        \n        train_perc = train_perc\n        valid_perc = valid_perc\n        \n        if trn_val_tst == 0:\n            # Create dataset for trainloader\n            self.signals = signals[0 : math.ceil(signals.shape[0] * train_perc)]\n            self.labels = labels[0 : math.ceil(signals.shape[0] * train_perc)]\n        elif trn_val_tst == 1:\n            # Create dataset for valloader\n            self.signals = signals[math.ceil(signals.shape[0] * train_perc) : math.ceil(signals.shape[0] * valid_perc)]\n            self.labels = labels[math.ceil(signals.shape[0] * train_perc) : math.ceil(signals.shape[0] * valid_perc)] \n        else:\n            # Create dataset for testloader\n            self.signals = signals[math.ceil(signals.shape[0] * valid_perc) :]    \n            self.labels = labels[math.ceil(signals.shape[0] * valid_perc) :]   \n            \n        self.signals = torch.from_numpy(self.signals)\n        self.labels = torch.from_numpy(self.labels)\n        \n        \n    # Define len function\n    def __len__(self):\n        return len(self.labels)\n\n    # Define getitem function\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n   \n        sample = self.signals[idx,:]\n        labels = self.labels[idx]\n                    \n        return sample, labels","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:03.034678Z","iopub.execute_input":"2023-01-09T03:48:03.036197Z","iopub.status.idle":"2023-01-09T03:48:03.048497Z","shell.execute_reply.started":"2023-01-09T03:48:03.036143Z","shell.execute_reply":"2023-01-09T03:48:03.047303Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128   \n\nsignals = pd.read_csv('../input/nn-test-data-2/scrappie_signals.csv').to_numpy()\nlabels = pd.read_csv('../input/nn-test-data-2/scrappie_labels.csv').to_numpy()\n\nrowOrder = []\nfor i in range(256):\n    for j in range(100):\n        rowOrder.append(j * 100 + i)\nsignals = np.expand_dims(signals[rowOrder],1)\nlabels = np_utils.to_categorical(labels[rowOrder] - 1, num_classes=256)\n\n# Call training dataset and create the trainloader.\ntrainset = Squiggles(trn_val_tst = 0, signals = signals, labels = labels, train_perc = 0.66, valid_perc = 1)  \ntrainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n\n# Call validation dataset and create the valloader.\nvalset = Squiggles(trn_val_tst = 1, signals = signals, labels = labels, train_perc = 0.66, valid_perc = 1) \nvalloader = DataLoader(dataset=valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:03.774876Z","iopub.execute_input":"2023-01-09T03:48:03.775606Z","iopub.status.idle":"2023-01-09T03:48:05.204761Z","shell.execute_reply.started":"2023-01-09T03:48:03.775567Z","shell.execute_reply":"2023-01-09T03:48:05.203639Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Classifier_256(LightningModule):\n    def __init__(self, learning_rate=0.001, train_loader=trainloader, val_loader=valloader):\n        super().__init__()\n        \n        self.loss_fn = nn.CrossEntropyLoss()\n        \n        self.learning_rate = learning_rate\n        self.train_loader=train_loader\n        self.val_loader=val_loader\n                \n        self.train_accuracy = Accuracy() \n        self.val_accuracy = Accuracy()\n        \n        self.sm = nn.Softmax()\n        \n        self.conv1 = nn.Conv1d(1, 8, 8)\n        self.act_conv1 = nn.ELU()\n        \n        self.conv2 = nn.Conv1d(8, 16, 4, dilation=2)\n        self.act_conv2 = nn.ReLU()\n        \n        self.conv3 = nn.Conv1d(16, 32, 4, dilation=4)\n        self.act_conv3 = nn.ReLU()\n        \n        self.conv_dropout = nn.Dropout(p=0.3)\n        \n        self.pool = nn.MaxPool1d(8,stride=6)\n        self.act_pool = nn.ReLU()\n        self.pool_dropout = nn.Dropout(p=0.5)\n\n        self.fc1 = nn.Linear(640,512) \n        self.act_fc1 = nn.ELU()\n        self.fc1_dropout = nn.Dropout(p=0.5)\n\n        self.fc2 = nn.Linear(512,256) # The output FC layer\n            \n    def forward(self, x):\n        x = x.float()\n        x = torch.reshape(x, (-1, 1, 152))\n        \n        #Pass input through conv layers\n        out = self.conv1(x)\n        out = self.act_conv1(out)\n        \n        out = self.conv2(out)\n        out = self.act_conv2(out)\n        \n        out = self.conv3(out)\n        out = self.act_conv3(out)\n        \n        out = self.conv_dropout(out)\n        \n        out = self.pool(out)\n        out = self.act_pool(out)\n        out = self.pool_dropout(out)\n        \n        out = out.view(-1,640)\n        out = self.fc1(out)\n        out = self.act_fc1(out)\n        out = self.fc1_dropout(out)\n        \n        out = self.fc2(out)\n        \n        return out\n    \n    def training_step(self, batch, batch_idx):\n        # Write training step\n        loss = self.compute_loss(batch)\n        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x, y = batch\n        self.train_accuracy.update(self(x).argmax(1), y.argmax(1))\n        self.log(\"train_acc\", self.train_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        # Write validation step\n        loss = self.compute_loss(batch)\n        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x, y = batch\n        self.val_accuracy.update(self(x).argmax(1), y.argmax(1))\n        self.log(\"val_acc\", self.val_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n        \n    def compute_loss(self, batch):\n        x_batch, y_batch = batch\n        logits = self(x_batch)\n        \n        loss = self.loss_fn(logits, y_batch)\n        return loss\n\n    def predict(self, signals):\n        logits = self(signals)\n        preds = self.sm(logits)\n        return preds\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    ####################\n    # DATA RELATED HOOKS\n    ####################\n\n    def train_dataloader(self):\n        return self.train_loader\n    \n    def val_dataloader(self):\n        return self.val_loader","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:05.206879Z","iopub.execute_input":"2023-01-09T03:48:05.207243Z","iopub.status.idle":"2023-01-09T03:48:05.230366Z","shell.execute_reply.started":"2023-01-09T03:48:05.207197Z","shell.execute_reply":"2023-01-09T03:48:05.229085Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/kaggle/working/logs_classifier_scrappie')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:05.690860Z","iopub.execute_input":"2023-01-09T03:48:05.691275Z","iopub.status.idle":"2023-01-09T03:48:05.696461Z","shell.execute_reply.started":"2023-01-09T03:48:05.691225Z","shell.execute_reply":"2023-01-09T03:48:05.695174Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model_classifier = Classifier_256()\n# # Define checkpoint callback function to save best model\n# checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n#                                       dirpath='logs_classifier_scrappie/',\n#                                       save_top_k=1,\n#                                       mode=\"min\",\n#                                       every_n_epochs=1)\n\n# # Train and test the model\n# trainer = Trainer(\n#     accelerator=\"auto\",\n#     devices=1 if torch.cuda.is_available() else None,  \n#     max_epochs=150,\n#     callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n#     logger=CSVLogger(save_dir='logs_classifier_scrappie/'),\n#     deterministic=True\n# )\n\n# print(model_classifier)\n# trainer.fit(model_classifier)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:06.112463Z","iopub.execute_input":"2023-01-09T03:48:06.112852Z","iopub.status.idle":"2023-01-09T03:48:06.118599Z","shell.execute_reply.started":"2023-01-09T03:48:06.112820Z","shell.execute_reply":"2023-01-09T03:48:06.117426Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # EDIT BEFORE RUNNING\n\nmodel_classifier = Classifier_256()\ncheckpoint = torch.load('/kaggle/working/logs_classifier_scrappie/epoch=68-step=9108.ckpt', map_location=torch.device('cpu'))\nmodel_classifier.load_state_dict(checkpoint['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:06.827822Z","iopub.execute_input":"2023-01-09T03:48:06.828219Z","iopub.status.idle":"2023-01-09T03:48:06.857174Z","shell.execute_reply.started":"2023-01-09T03:48:06.828187Z","shell.execute_reply":"2023-01-09T03:48:06.856315Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Call training dataset and create the trainloader.\n\nBATCH_SIZE = 2048\n\nrSquiggles = pd.read_csv('../input/nn-real-data-train-d1s1-1/real_signals_tr_d1s1.csv').to_numpy()\nrLabels = pd.read_csv('../input/nn-real-data-train-d1s1-1/real_labels_tr_d1s1.csv').to_numpy()\n\nrSquiggles = np.expand_dims(rSquiggles,1)\nrLabels = np_utils.to_categorical(rLabels - 1, num_classes=256)\nrSquiggles, rLabels = shuffle(rSquiggles, rLabels)\n\ntrainset = Squiggles(trn_val_tst = 0, signals=rSquiggles, labels=rLabels, train_perc = 0.6, valid_perc = 1)  \ntrainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True)\nmodel_classifier.train_loader = trainloader\n\n# Call validation dataset and create the valloader.\nvalset = Squiggles(trn_val_tst = 1, signals=rSquiggles, labels=rLabels, train_perc = 0.6, valid_perc = 1) \nvalloader = DataLoader(dataset=valset, batch_size=BATCH_SIZE, shuffle=False)\nmodel_classifier.val_loader = valloader","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:07.231614Z","iopub.execute_input":"2023-01-09T03:48:07.232706Z","iopub.status.idle":"2023-01-09T03:48:07.545726Z","shell.execute_reply.started":"2023-01-09T03:48:07.232659Z","shell.execute_reply":"2023-01-09T03:48:07.544272Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for name, param in model_classifier.named_parameters(): \n    if (name == 'fc1.weight'):\n        break\n    else:\n        param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:08.038581Z","iopub.execute_input":"2023-01-09T03:48:08.038983Z","iopub.status.idle":"2023-01-09T03:48:08.045481Z","shell.execute_reply.started":"2023-01-09T03:48:08.038950Z","shell.execute_reply":"2023-01-09T03:48:08.044503Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree('/kaggle/working/logs_classifier')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:08.439140Z","iopub.execute_input":"2023-01-09T03:48:08.439566Z","iopub.status.idle":"2023-01-09T03:48:08.444420Z","shell.execute_reply.started":"2023-01-09T03:48:08.439529Z","shell.execute_reply":"2023-01-09T03:48:08.443502Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Define checkpoint callback function to save best model\n# checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n#                                       dirpath='logs_classifier/',\n#                                       save_top_k=1,\n#                                       mode=\"min\",\n#                                       every_n_epochs=1)\n\n# # Train and test the model\n# trainer = Trainer(\n#     accelerator=\"auto\",\n#     devices=1 if torch.cuda.is_available() else None,  \n#     max_epochs=400,\n#     callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n#     logger=CSVLogger(save_dir='logs_classifier/'),\n#     deterministic=True\n# )\n\n# trainer.fit(model_classifier)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:10.622134Z","iopub.execute_input":"2023-01-09T03:48:10.622563Z","iopub.status.idle":"2023-01-09T03:48:10.628777Z","shell.execute_reply.started":"2023-01-09T03:48:10.622527Z","shell.execute_reply":"2023-01-09T03:48:10.627672Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Recover model\n\n# model_classifier = Classifier_256()\ncheckpoint = torch.load('/kaggle/working/logs_classifier/epoch=262-step=526.ckpt', map_location=torch.device('cpu'))\nmodel_classifier.load_state_dict(checkpoint['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:11.406672Z","iopub.execute_input":"2023-01-09T03:48:11.407816Z","iopub.status.idle":"2023-01-09T03:48:11.422003Z","shell.execute_reply.started":"2023-01-09T03:48:11.407754Z","shell.execute_reply":"2023-01-09T03:48:11.421122Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"traing_data = pd.read_csv('/kaggle/working/logs_classifier/lightning_logs/version_0/metrics.csv')\nprint(f'maximum val_acc: {traing_data[\"val_acc\"][traing_data[\"val_loss\"].argmin(0)]}')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:12.241427Z","iopub.execute_input":"2023-01-09T03:48:12.242551Z","iopub.status.idle":"2023-01-09T03:48:12.256687Z","shell.execute_reply.started":"2023-01-09T03:48:12.242501Z","shell.execute_reply":"2023-01-09T03:48:12.255454Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"maximum val_acc: 0.907764732837677\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 128\n\nrLabels_d = np.ones((rSquiggles.shape[0], 1))\nfLabels_d = np.zeros((signals.shape[0], 1))\n\ndLabels = np.concatenate((rLabels_d, fLabels_d))\n\nrSquiggles_temp = np.concatenate((rSquiggles, np.expand_dims(rLabels, 1)), 2)\nsignals_temp = np.concatenate((signals, np.expand_dims(labels, 1)), 2)\n\ndSquiggles = np.concatenate((rSquiggles_temp, signals_temp))\ndSquiggles, dLabels = shuffle(dSquiggles, dLabels)\n\ntrainset = Squiggles(trn_val_tst = 0, signals=dSquiggles, labels=dLabels, train_perc = 0.8, valid_perc = 1)  \ntrainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n\n# Call validation dataset and create the valloader.\nvalset = Squiggles(trn_val_tst = 1, signals=dSquiggles, labels=dLabels, train_perc = 0.8, valid_perc = 1) \nvalloader = DataLoader(dataset=valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:12.754436Z","iopub.execute_input":"2023-01-09T03:48:12.755131Z","iopub.status.idle":"2023-01-09T03:48:12.903853Z","shell.execute_reply.started":"2023-01-09T03:48:12.755093Z","shell.execute_reply":"2023-01-09T03:48:12.902668Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Discriminator(LightningModule):\n    def __init__(self, learning_rate=0.001, train_loader=trainloader, val_loader=valloader):\n        super().__init__()\n        \n        self.loss_fn = nn.BCELoss()\n        \n        self.learning_rate = learning_rate\n        self.train_loader= train_loader\n        self.val_loader= val_loader\n                \n        self.train_accuracy_real = Accuracy() \n        self.train_accuracy_fake = Accuracy() \n        self.val_accuracy_real = Accuracy()\n        self.val_accuracy_fake = Accuracy()\n        \n        self.embedding = nn.Embedding(256, 50)\n        self.class_fc = nn.Linear(50, 152) # i.e. (1x152)   \n        self.act_class_fc = nn.ReLU()\n        \n        self.conv1 = nn.Conv1d(2, 8, 8)\n        self.act_conv1 = nn.ELU()\n        \n        self.conv2 = nn.Conv1d(8, 16, 4, dilation=2)\n        self.act_conv2 = nn.ReLU()\n        \n        self.conv3 = nn.Conv1d(16, 32, 4, dilation=4)\n        self.act_conv3 = nn.ReLU()\n        \n        self.conv_dropout = nn.Dropout(p=0.3)\n        \n        self.pool = nn.MaxPool1d(8,stride=6)\n        self.act_pool = nn.ReLU()\n        self.pool_dropout = nn.Dropout(p=0.5)\n\n        self.fc1 = nn.Linear(640,150) \n        self.act_fc1 = nn.ELU()\n        self.fc1_dropout = nn.Dropout(p=0.5)\n\n        self.fc2 = nn.Linear(150,1) # The output FC layer\n        self.sigmoid = nn.Sigmoid()\n        \n            \n    def forward(self, x):\n        x = torch.reshape(x, (-1, 1, 408)).float()\n        \n        signal = x[:,:,0:152]\n        s = torch.reshape(signal, (-1,1,152))\n        \n        label = x[:,:,152:].argmax(2)\n        c = self.embedding(label)\n        c = self.class_fc(c)\n        c = self.act_class_fc(c)\n        c = torch.reshape(c, (-1,1,152))\n        \n        out = torch.cat((s,c), dim=1) # (-1, 2, 152)\n        \n        out = self.conv1(out)\n        out = self.act_conv1(out)\n        \n        out = self.conv2(out)\n        out = self.act_conv2(out)\n        \n        out = self.conv3(out)\n        out = self.act_conv3(out)\n        \n        out = self.conv_dropout(out)\n        \n        out = self.pool(out)\n        out = self.act_pool(out)\n        out = self.pool_dropout(out)\n        \n        out = out.view(-1,640)\n        out = self.fc1(out)\n        out = self.act_fc1(out)\n        out = self.fc1_dropout(out)\n        \n        out = self.fc2(out)\n        out = self.sigmoid(out)\n        \n        return out\n    \n    def training_step(self, batch, batch_idx):\n        # Write training step\n        loss = self.compute_loss(batch)\n        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x, y = batch\n        \n        real = x[y == 1]\n        fake = x[y == 0]\n        \n        real_out = torch.reshape(self(real), (-1,1))\n        fake_out = torch.reshape(self(fake), (-1,1))\n        \n        y_real = torch.reshape(y[y == 1], real_out.shape)\n        y_fake = torch.reshape(y[y == 0], fake_out.shape)\n        \n        if (real_out.shape[0] != 0):\n            self.train_accuracy_real.update(real_out, y_real.int())\n            self.log(\"train_acc_real\", self.train_accuracy_real, prog_bar=True, on_step=False, on_epoch=True)\n        \n        if (fake_out.shape[0] != 0):\n            self.train_accuracy_fake.update(fake_out, y_fake.int())\n            self.log(\"train_acc_fake\", self.train_accuracy_fake, prog_bar=True, on_step=False, on_epoch=True)\n\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        # Write validation step\n        loss = self.compute_loss(batch)\n        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x,y = batch\n        \n        real = x[y == 1]\n        fake = x[y == 0]\n        \n        real_out = torch.reshape(self(real), (-1,1))\n        fake_out = torch.reshape(self(fake), (-1,1))\n        \n        y_real = torch.reshape(y[y == 1], real_out.shape)\n        y_fake = torch.reshape(y[y == 0], fake_out.shape)\n        \n        if (real_out.shape[0] != 0):\n            self.val_accuracy_real.update(real_out, y_real.int())\n            self.log(\"val_acc_real\", self.val_accuracy_real, prog_bar=True, on_step=False, on_epoch=True)\n        \n        if (fake_out.shape[0] != 0):\n            self.val_accuracy_fake.update(fake_out, y_fake.int())\n            self.log(\"val_acc_fake\", self.val_accuracy_fake, prog_bar=True, on_step=False, on_epoch=True)\n        \n    def compute_loss(self, batch):\n        x, y = batch\n        \n        real = x[y == 1]\n        fake = x[y == 0]\n        \n        real_out = torch.reshape(self(real), (-1,1))\n        fake_out = torch.reshape(self(fake), (-1,1))\n        \n        y_real = torch.reshape(y[y == 1], real_out.shape)\n        y_fake = torch.reshape(y[y == 0], fake_out.shape)\n        \n        if (real_out.shape[0] != 0): \n            real_loss = self.loss_fn(real_out.float(), y_real.float())\n        else:\n            real_loss = 0\n            \n        if (fake_out.shape[0] != 0):\n            fake_loss = self.loss_fn(fake_out.float(), y_fake.float())\n        else:\n            fake_loss = 0\n        \n        loss = (real_loss + fake_loss) / 2\n        \n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    ####################\n    # DATA RELATED HOOKS\n    ####################\n\n    def train_dataloader(self):\n        return self.train_loader\n    \n    def val_dataloader(self):\n        return self.val_loader","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:48:13.315648Z","iopub.execute_input":"2023-01-09T03:48:13.316787Z","iopub.status.idle":"2023-01-09T03:48:13.352558Z","shell.execute_reply.started":"2023-01-09T03:48:13.316725Z","shell.execute_reply":"2023-01-09T03:48:13.351477Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree('/kaggle/working/logs_discriminator')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:49:11.581713Z","iopub.execute_input":"2023-01-09T03:49:11.582126Z","iopub.status.idle":"2023-01-09T03:49:11.589782Z","shell.execute_reply.started":"2023-01-09T03:49:11.582090Z","shell.execute_reply":"2023-01-09T03:49:11.588303Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# model_discriminator = Discriminator()\n\n# # Define checkpoint callback function to save best model\n# checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n#                                       dirpath='logs_discriminator/',\n#                                       save_top_k=1,\n#                                       mode=\"min\",\n#                                       every_n_epochs=1)\n\n# # Train and test the model\n# trainer = Trainer(\n#     accelerator=\"auto\",\n#     devices=1 if torch.cuda.is_available() else None,  \n#     max_epochs=10,\n#     callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n#     logger=CSVLogger(save_dir='logs_discriminator/'),\n#     deterministic=True\n# )\n\n# trainer.fit(model_discriminator)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:49:15.932589Z","iopub.execute_input":"2023-01-09T03:49:15.933004Z","iopub.status.idle":"2023-01-09T03:50:48.276602Z","shell.execute_reply.started":"2023-01-09T03:49:15.932967Z","shell.execute_reply":"2023-01-09T03:50:48.275537Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1cb96f9b9240859ae96bc6573cd98b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# Recover model\n\nmodel_discriminator = Discriminator()\ncheckpoint = torch.load('/kaggle/working/logs_discriminator/epoch=7-step=1552.ckpt', map_location=torch.device('cpu'))\nmodel_discriminator.load_state_dict(checkpoint['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:18.257213Z","iopub.execute_input":"2023-01-09T03:51:18.257624Z","iopub.status.idle":"2023-01-09T03:51:18.282147Z","shell.execute_reply.started":"2023-01-09T03:51:18.257591Z","shell.execute_reply":"2023-01-09T03:51:18.280944Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"traing_data = pd.read_csv('/kaggle/working/logs_discriminator/lightning_logs/version_0/metrics.csv')\nprint(f'maximum val_acc_real: {traing_data[\"val_acc_real\"][traing_data[\"val_loss\"].argmin(0)]}')\nprint(f'maximum val_acc_fake: {traing_data[\"val_acc_fake\"][traing_data[\"val_loss\"].argmin(0)]}')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:27.431204Z","iopub.execute_input":"2023-01-09T03:51:27.431683Z","iopub.status.idle":"2023-01-09T03:51:27.445299Z","shell.execute_reply.started":"2023-01-09T03:51:27.431643Z","shell.execute_reply":"2023-01-09T03:51:27.443951Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"maximum val_acc_real: 0.9800724387168884\nmaximum val_acc_fake: 0.998030722141266\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 128\nnSquiggles = np.concatenate((signals, np.expand_dims(labels, 1)), axis=2)\nnSquiggles, nLabels = shuffle(nSquiggles, labels)\n\ntrainset = Squiggles(trn_val_tst = 0, signals=nSquiggles, labels=nLabels, train_perc = 0.7, valid_perc = 1)  \ntrainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n\n# Call validation dataset and create the valloader.\nvalset = Squiggles(trn_val_tst = 1, signals=nSquiggles, labels=nLabels, train_perc = 0.7, valid_perc = 1) \nvalloader = DataLoader(dataset=valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:30.199461Z","iopub.execute_input":"2023-01-09T03:51:30.200709Z","iopub.status.idle":"2023-01-09T03:51:30.303433Z","shell.execute_reply.started":"2023-01-09T03:51:30.200665Z","shell.execute_reply":"2023-01-09T03:51:30.301938Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class Generator(LightningModule):\n    def __init__(self, learning_rate=0.001, loss_weights = [1,1,1,0], train_loader=trainloader, val_loader=valloader):\n        super().__init__()\n        \n        self.loss_D = nn.BCELoss()\n        self.loss_C = nn.CrossEntropyLoss()\n        self.MSE = nn.MSELoss()\n        self.L1 = nn.L1Loss()\n\n        self.learning_rate = learning_rate\n        self.train_loader= train_loader\n        self.val_loader= val_loader\n                \n        self.train_classifier_accuracy = Accuracy() \n        self.val_classifier_accuracy = Accuracy()\n        self.train_discriminator_accuracy = Accuracy() \n        self.val_discriminator_accuracy = Accuracy()\n        \n        self.loss_weights = loss_weights\n        \n        self.embedding = nn.Embedding(256, 50)\n        self.signal_fc = nn.Linear(152, 1722) # re-shape to (41x42) (41 channels)\n        self.class_fc = nn.Linear(50, 42) # i.e. (1x42)\n        \n        self.conv_t1 = nn.ConvTranspose1d(42, 20, 9, stride=2) # out: \n        self.bn = nn.BatchNorm1d(20)\n        \n        self.conv_t2 = nn.ConvTranspose1d(20, 1, 8, stride=2, padding=18) # out: \n\n    def forward(self, x):\n        x = torch.reshape(x, (-1,1,408)).float()\n        signal = x[:,0,0:152]\n        label = x[:,0,152:408].argmax(1)\n        \n        c = self.embedding(label)\n        c = self.class_fc(c)\n        c = torch.reshape(c, (-1,1,42))\n        \n        s = self.signal_fc(signal)\n        s = torch.relu(s)\n        s = torch.reshape(s, (-1,41,42))\n        \n        out = torch.cat((s,c), dim=1)\n        out = self.conv_t1(out)\n        out = self.bn(out)\n        out = torch.relu(out)\n        \n        out = self.conv_t2(out)\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        # Write training step\n        loss, class_probabilities, discriminator_probabilities, l_MSE, l_C, l_D, l_L1 = self.compute_loss(batch)\n        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        self.log(\"MSE_loss\", l_MSE, prog_bar=True, on_step=False, on_epoch=True)\n        self.log(\"C_loss\", l_C, prog_bar=True, on_step=False, on_epoch=True)\n        self.log(\"D_loss\", l_D, prog_bar=True, on_step=False, on_epoch=True)\n        self.log(\"L1_loss\", l_L1, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x, y = batch\n        self.train_classifier_accuracy.update(class_probabilities.argmax(1), y.argmax(1))\n        self.log(\"train_class_acc\", self.train_classifier_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n        \n        self.train_discriminator_accuracy.update(discriminator_probabilities, torch.ones(discriminator_probabilities.shape).int())\n        self.log(\"train_disc_acc\", self.train_discriminator_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n        \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        # Write validation step\n        loss, class_probabilities, discriminator_probabilities, l_MSE, l_C, l_D, l_L1 = self.compute_loss(batch)\n        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n        \n        x, y = batch\n        self.val_classifier_accuracy.update(class_probabilities.argmax(1), y.argmax(1))\n        self.log(\"val_class_acc\", self.val_classifier_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n        \n        self.val_discriminator_accuracy.update(discriminator_probabilities, torch.ones(discriminator_probabilities.shape).int())\n        self.log(\"val_disc_acc\", self.val_discriminator_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n        \n    def compute_loss(self, batch):\n        x_batch, y_batch = batch\n        \n        y_batch_temp = torch.unsqueeze(y_batch, 1)\n        noisy_signal_modded = torch.cat((self(x_batch),y_batch_temp), dim=2)\n        l_MSE = self.MSE(x_batch.float(), noisy_signal_modded.float()).float()\n        l_L1 = self.L1(x_batch.float(), noisy_signal_modded.float()).float()\n        \n        model_discriminator.eval()\n        real_fake = model_discriminator(noisy_signal_modded)\n        l_D = self.loss_D(real_fake, torch.ones(real_fake.shape))\n        \n        model_classifier.eval()\n        c_logits = model_classifier(self(x_batch))\n        l_C = self.loss_C(c_logits, y_batch) \n        \n        loss = self.loss_weights[0]*l_C + self.loss_weights[1]*l_D + self.loss_weights[2]*l_MSE + self.loss_weights[3]*l_L1\n        \n        class_probabilities = model_classifier.predict(self(x_batch))\n        return loss, class_probabilities, real_fake, l_MSE, l_C, l_D, l_L1\n    \n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n#         lr_scheduler = {\n#         'scheduler' : torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5),\n#         'monitor' : 'val_loss'}\n        \n        return optimizer\n\n    ####################\n    # DATA RELATED HOOKS\n    ####################\n\n    def train_dataloader(self):\n        return self.train_loader\n    \n    def val_dataloader(self):\n        return self.val_loader\n\n    def test_dataloader(self):\n        return self.test_loader","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:31.442702Z","iopub.execute_input":"2023-01-09T03:51:31.444911Z","iopub.status.idle":"2023-01-09T03:51:31.493431Z","shell.execute_reply.started":"2023-01-09T03:51:31.444819Z","shell.execute_reply":"2023-01-09T03:51:31.491672Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree('/kaggle/working/logs_generator')","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:13:47.102381Z","iopub.execute_input":"2023-01-08T13:13:47.102811Z","iopub.status.idle":"2023-01-08T13:13:47.107797Z","shell.execute_reply.started":"2023-01-08T13:13:47.102780Z","shell.execute_reply":"2023-01-08T13:13:47.106354Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# model_generator = Generator()\n# checkpoint = torch.load('/kaggle/working/logs_generator/epoch=110-step=6860.ckpt', map_location=torch.device('cpu'))\n# model_generator.load_state_dict(checkpoint['state_dict'])\n\n# # Define checkpoint callback function to save best model\n# checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n#                                       dirpath='logs_generator/',\n#                                       save_top_k=1,\n#                                       mode=\"min\",\n#                                       every_n_epochs=1)\n\n# early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=20, verbose=True, mode=\"min\")\n\n# # Train and test the model\n# trainer = Trainer(\n#     accelerator=\"auto\",\n#     devices=1 if torch.cuda.is_available() else None,  \n#     max_epochs=200,\n#     callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback, early_stop_callback],\n#     logger=CSVLogger(save_dir='logs_generator/'),\n#     deterministic=True\n    \n# )\n\n# # trainer.tune(model_generator)\n\n# trainer.fit(model_generator)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:47:03.963140Z","iopub.execute_input":"2023-01-08T13:47:03.963560Z","iopub.status.idle":"2023-01-08T13:47:03.978316Z","shell.execute_reply.started":"2023-01-08T13:47:03.963525Z","shell.execute_reply":"2023-01-08T13:47:03.977065Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Recover model\n\nmodel_generator = Generator()\ncheckpoint = torch.load('/kaggle/working/logs_generator/epoch=110-step=15540.ckpt', map_location=torch.device('cpu'))\nmodel_generator.load_state_dict(checkpoint['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:35.496693Z","iopub.execute_input":"2023-01-09T03:51:35.497091Z","iopub.status.idle":"2023-01-09T03:51:35.550801Z","shell.execute_reply.started":"2023-01-09T03:51:35.497059Z","shell.execute_reply":"2023-01-09T03:51:35.549093Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"traing_data = pd.read_csv('/kaggle/working/logs_generator/lightning_logs/version_0/metrics.csv')\nprint(f'maximum val_class_acc: {traing_data[\"val_class_acc\"][traing_data[\"val_loss\"].argmin(0)]}')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:51:36.717483Z","iopub.execute_input":"2023-01-09T03:51:36.717884Z","iopub.status.idle":"2023-01-09T03:51:36.750166Z","shell.execute_reply.started":"2023-01-09T03:51:36.717851Z","shell.execute_reply":"2023-01-09T03:51:36.748670Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"maximum val_class_acc: 0.9748697876930236\n","output_type":"stream"}]},{"cell_type":"code","source":"shutil.rmtree('/kaggle/working/logs_generator_GAN')\nshutil.rmtree('/kaggle/working/logs_discriminator_GAN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel_generator.loss_weights = [1,1,0,0]\n\nclassifier_accuracy_on_generator = [] # after updating generator\ndiscriminator_accuracy_on_generator = []\n\ndiscriminator_accuracy_real = [] # after updating discriminator\ndiscriminator_accuracy_fake = []\n\nog_train_signals = model_discriminator.train_loader.dataset.signals\nog_train_labels = model_discriminator.train_loader.dataset.labels\n\nog_val_signals = model_discriminator.val_loader.dataset.signals\nog_val_labels = model_discriminator.val_loader.dataset.labels\n\ng_epochs = 10\nsuper_epoch = 0\n\nwhile (g_epochs < 150 or super_epoch < 30):\n    print(f'EPOCH {super_epoch} COMMENCING\\n')\n    \n    # TRAIN GENERATOR\n    print(f'Epoch {super_epoch}: Training Generator')\n    model_generator.train()\n    model_discriminator.eval()\n    checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n                                          dirpath='logs_generator_GAN/',\n                                          save_top_k=1,\n                                          mode=\"min\",\n                                          every_n_epochs=1)\n\n    # Train and test the model\n    trainer = Trainer(\n        accelerator=\"auto\",\n        devices=1 if torch.cuda.is_available() else None,  \n        max_epochs=g_epochs,\n        callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n        logger=CSVLogger(save_dir='logs_generator_GAN/'),\n        deterministic=True\n    )\n\n    trainer.fit(model_generator)\n    \n    # UPDATE STATS\n    traing_data = pd.read_csv(f'/kaggle/working/logs_generator_GAN/lightning_logs/version_{super_epoch}/metrics.csv')\n    classifier_accuracy_on_generator.append(traing_data[\"val_class_acc\"][traing_data[\"val_loss\"].argmin(0)])\n    discriminator_accuracy_on_generator.append(traing_data[\"val_disc_acc\"][traing_data[\"val_loss\"].argmin(0)])\n    print(f'Classifier Accuracy on Generator: {100*classifier_accuracy_on_generator[-1]}')\n    print(f'Mean Discriminator Conviction: {100*discriminator_accuracy_on_generator[-1]}')\n    \n    # OBTAIN GENERATOR OUTPUT\n    model_generator.eval()\n    gen_train_out_raw = model_generator(model_generator.train_loader.dataset.signals) # generator output for train/val sets\n    gen_val_out_raw = model_generator(model_generator.val_loader.dataset.signals)\n\n    gen_train_out = torch.cat((gen_train_out_raw,torch.unsqueeze(model_generator.train_loader.dataset.labels, 1)), 2) # concatenating labels\n    train_labels = torch.zeros((gen_train_out_raw.shape[0], 1)) # 'fake' labels for trainset\n\n    gen_val_out = torch.cat((gen_val_out_raw,torch.unsqueeze(model_generator.val_loader.dataset.labels, 1)), 2)\n    val_labels = torch.zeros((gen_val_out_raw.shape[0], 1))\n    \n    # PREPARE NEW DATALOADER FOR DISCRIMINATOR\n    BATCH_SIZE = 2048\n    updated_discriminator_train_data = torch.cat((og_train_signals, gen_train_out), 0)\n    updated_discriminator_train_labels = torch.cat((og_train_labels, train_labels), 0)\n\n    updated_discriminator_val_data = torch.cat((og_val_signals, gen_val_out), 0)\n    updated_discriminator_val_labels = torch.cat((og_val_labels, val_labels), 0)\n\n    updated_discriminator_train_data, updated_discriminator_train_labels = shuffle(updated_discriminator_train_data, updated_discriminator_train_labels)\n    updated_discriminator_val_data, updated_discriminator_val_labels = shuffle(updated_discriminator_val_data, updated_discriminator_val_labels)\n    \n    updated_discriminator_trainset = Squiggles(trn_val_tst = 0, signals=updated_discriminator_train_data.detach().numpy(), labels=updated_discriminator_train_labels.detach().numpy(), train_perc = 1)  \n    updated_discriminator_trainloader = DataLoader(dataset=updated_discriminator_trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n\n    # Call validation dataset and create the valloader.\n    updated_discriminator_valset = Squiggles(trn_val_tst = 0, signals=updated_discriminator_val_data.detach().numpy(), labels=updated_discriminator_val_labels.detach().numpy(), train_perc = 1) \n    updated_discriminator_valloader = DataLoader(dataset=updated_discriminator_valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n    \n    model_discriminator.train_loader = updated_discriminator_trainloader\n    model_discriminator.val_loader = updated_discriminator_valloader\n\n    print(f'Epoch {super_epoch}: Training Discriminator\\n')\n    model_discriminator.train()\n    # Define checkpoint callback function to save best model\n    checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n                                          dirpath='logs_discriminator_GAN/',\n                                          save_top_k=1,\n                                          mode=\"min\",\n                                          every_n_epochs=1)\n\n    # Train and test the model\n    trainer = Trainer(\n        accelerator=\"auto\",\n        devices=1 if torch.cuda.is_available() else None,  \n        max_epochs=3,\n        callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n        logger=CSVLogger(save_dir='logs_discriminator_GAN/'),\n        deterministic=True\n    )\n\n    trainer.fit(model_discriminator)\n    \n    traing_data = pd.read_csv(f'/kaggle/working/logs_discriminator_GAN/lightning_logs/version_{super_epoch}/metrics.csv')\n    discriminator_accuracy_real.append(traing_data[\"val_acc_real\"][traing_data[\"val_loss\"].argmin(0)])\n    discriminator_accuracy_fake.append(traing_data[\"val_acc_fake\"][traing_data[\"val_loss\"].argmin(0)])\n    print(f'Discriminator Accuracy on Real Data: {discriminator_accuracy_real[-1]}')\n    print(f'Discriminator Accuracy on Fake Data: {discriminator_accuracy_fake[-1]}')\n    \n    super_epoch = super_epoch + 1\n    if (discriminator_accuracy_on_generator[-1] < 0.7):\n        g_epochs = g_epochs + 10","metadata":{"execution":{"iopub.status.busy":"2023-01-09T03:52:28.154171Z","iopub.execute_input":"2023-01-09T03:52:28.154662Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"EPOCH 0 COMMENCING\n\nEpoch 0: Training Generator\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d3be33156648f69263d191078b60d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Classifier Accuracy on Generator: 98.3984351158142\nMean Discriminator Conviction: 98.9062488079071\nEpoch 0: Training Discriminator\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  category=PossibleUserWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13313ec405444c33be3dfb79c199e4d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Discriminator Accuracy on Real Data: 0.9610507488250732\nDiscriminator Accuracy on Fake Data: 0.9819720983505248\nEPOCH 1 COMMENCING\n\nEpoch 1: Training Generator\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /kaggle/working/logs_generator_GAN exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608c028b30bc448c8a33dce1e2f964c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# #    \n# s = 0\n\n# sample_input_signal = model_generator.val_loader.dataset.signals[0]\n# sample_input_label = model_generator.val_loader.dataset.labels[0].argmax()\n# PLOT SAMPLE\n#     g_out = model_generator(sample_input_signal)\n#     real = model_generator.train_loader.dataset.signals[model_generator.train_loader.dataset.labels.argmax(1) == sample_input_label][0]\n    \n#     pClass = model_classifier.predict(sample_input_signal[0,0:152])\n#     pReal = model_discriminator(sample_input_signal)\n\n#     fig = plt.figure(figsize=(10,10))\n#     fig.suptitle(f'Classifier is {round(pClass.max().item()*100,1)}% sure that class is {pClass.argmax().item()}\\nClass is actually {sample_input_label}\\nDiscriminator is {round(pReal.item()*100,1)}% convinced')\n\n#     plt.subplot(2, 2, 1)\n#     plt.plot(np.arange(1,152 + 1), g_out[0,0,:].detach())\n#     plt.title(f'Noised Signal of Class {sample_input_label}')\n    \n#     plt.subplot(2, 2, 2)\n#     plt.plot(np.arange(1,152 + 1), sample_input_signal[0,0:152])\n#     plt.title(f'Original Signal of Class {sample_input_label}')\n\n#     plt.subplot(2, 2, 3)\n#     plt.plot(np.arange(1,152 + 1), real[0,0:152])\n#     plt.title(f'Sample Real Signal of Class {sample_input_label}')","metadata":{"execution":{"iopub.status.busy":"2023-01-08T14:03:31.789324Z","iopub.execute_input":"2023-01-08T14:03:31.789815Z","iopub.status.idle":"2023-01-08T14:03:31.797561Z","shell.execute_reply.started":"2023-01-08T14:03:31.789778Z","shell.execute_reply":"2023-01-08T14:03:31.796231Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"model_generator.train()\ncheckpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n                                      dirpath='logs_generator_GAN_BEST/',\n                                      save_top_k=1,\n                                      mode=\"min\",\n                                      every_n_epochs=1)\n\n# Train and test the model\ntrainer = Trainer(\n    accelerator=\"auto\",\n    devices=1 if torch.cuda.is_available() else None,  \n    max_epochs=60,\n    callbacks=[TQDMProgressBar(refresh_rate=20), checkpoint_callback],\n    logger=CSVLogger(save_dir='logs_generator_GAN/'),\n    deterministic=True\n)\n\ntrainer.fit(model_generator)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T12:08:40.023583Z","iopub.status.idle":"2023-01-08T12:08:40.024055Z","shell.execute_reply.started":"2023-01-08T12:08:40.023821Z","shell.execute_reply":"2023-01-08T12:08:40.023841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel_classifier.eval()\nmodel_generator.eval()\nmodel_discriminator.eval()\n\ns = 2\nc = 42\n\ntrainset = model_generator.train_loader.dataset\n\nnoisy_signals = model_generator(trainset.signals).detach()\nnoisy_signals_labelled =  torch.cat((noisy_signals,torch.unsqueeze(trainset.labels, 1)), 2)\nd_acc = torch.mean(model_discriminator(noisy_signals_labelled).detach())\nprint(f'Discriminator accuracy: {100*d_acc}')\n\nnoisy_signals = noisy_signals[trainset.labels.argmax(1) == c]\nnoisy_signals_labelled = noisy_signals_labelled[trainset.labels.argmax(1) == c]\nlabels = trainset.labels[trainset.labels.argmax(1) == c]\n\nprint(trainset.labels.argmax(1).shape)\n\nprint(sum(trainset.labels.argmax(1) == c))\n\npClass = model_classifier.predict(noisy_signals)[s]\npReal = model_discriminator(noisy_signals_labelled)[s]\n\nfig = plt.figure(figsize=(10,10))\nfig.suptitle(f'Classifier is {round(pClass.max().item()*100,1)}% sure that class is {pClass.argmax(0).item()}\\nClass is {labels[s].argmax(0).item()}\\nDiscriminator is {round(pReal.item()*100,1)}% convinced')\n    \nplt.subplot(2, 2, 1)\nplt.plot(np.arange(1,152 + 1), noisy_signals[s][0])\nplt.title(f'Noised Signal of Class {c}')\n\nplt.subplot(2, 2, 2)\nprint(trainset.signals[trainset.labels.argmax(1) == c][s,0,0:152].shape)\nprint(np.arange(1,152 + 1).shape)\n\nplt.plot(np.arange(1,152 + 1), trainset.signals[trainset.labels.argmax(1) == c][s,0,0:152])\nplt.title(f'Original Scrappie Signal of Class {c}')\n\nplt.subplot(2, 2, 3)\nplt.plot(np.arange(1,152 + 1), rSquiggles[rLabels.argmax(1) == c][s][0])\nplt.title(f'Sample Real Signal of Class {c}')","metadata":{"execution":{"iopub.status.busy":"2023-01-08T12:08:40.025931Z","iopub.status.idle":"2023-01-08T12:08:40.026391Z","shell.execute_reply.started":"2023-01-08T12:08:40.026188Z","shell.execute_reply":"2023-01-08T12:08:40.026206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}